{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fcfbbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e7171af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
       "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
       "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
       "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
       "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
       "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
       "\n",
       "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
       "0       23.5     -215.0     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
       "1      -23.3      182.0       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
       "2      462.0     -267.0     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
       "3      299.0      132.0     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
       "4       12.0      119.0     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('H:/emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca91a4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2132 entries, 0 to 2131\n",
      "Columns: 2549 entries, # mean_0_a to label\n",
      "dtypes: float64(2548), object(1)\n",
      "memory usage: 41.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6460325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='label', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02dabb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# mean_0_a    0\n",
       "mean_1_a      0\n",
       "mean_2_a      0\n",
       "mean_3_a      0\n",
       "mean_4_a      0\n",
       "             ..\n",
       "fft_746_b     0\n",
       "fft_747_b     0\n",
       "fft_748_b     0\n",
       "fft_749_b     0\n",
       "label         0\n",
       "Length: 2549, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "# no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7618375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
      "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
      "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
      "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
      "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
      "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
      "\n",
      "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
      "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
      "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
      "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
      "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
      "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
      "\n",
      "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b  label  \n",
      "0       23.5     -215.0     280.00    -162.00    -162.00     280.00      2  \n",
      "1      -23.3      182.0       2.57     -31.60     -31.60       2.57      0  \n",
      "2      462.0     -267.0     281.00    -148.00    -148.00     281.00      1  \n",
      "3      299.0      132.0     -12.40       9.53       9.53     -12.40      1  \n",
      "4       12.0      119.0     -17.60      23.90      23.90     -17.60      0  \n",
      "\n",
      "[5 rows x 2549 columns]\n",
      "0    716\n",
      "2    708\n",
      "1    708\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "encode = ({'NEUTRAL': 0, 'POSITIVE': 1, 'NEGATIVE': 2} )\n",
    "#new dataset with replaced values\n",
    "df_encoded = df.replace(encode)\n",
    "\n",
    "print(df_encoded.head())\n",
    "print(df_encoded['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd8cad1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_encoded['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3b1c9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
       "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
       "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
       "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
       "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
       "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
       "\n",
       "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b  label  \n",
       "0       23.5     -215.0     280.00    -162.00    -162.00     280.00      2  \n",
       "1      -23.3      182.0       2.57     -31.60     -31.60       2.57      0  \n",
       "2      462.0     -267.0     281.00    -148.00    -148.00     281.00      1  \n",
       "3      299.0      132.0     -12.40       9.53       9.53     -12.40      1  \n",
       "4       12.0      119.0     -17.60      23.90      23.90     -17.60      0  \n",
       "\n",
       "[5 rows x 2549 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc51b6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132, 2548)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df_encoded.drop([\"label\"]  ,axis=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00d4d4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_encoded.loc[:,'label'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce734b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b5e64aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e52f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "063e2c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0],1,x.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],1,x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76a3eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 64)             668928    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 64)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 681,443\n",
      "Trainable params: 681,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(1,2548),activation=\"relu\",return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(100,return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(50))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f91a52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 2s 12ms/step - loss: 0.5248 - accuracy: 0.8346 - val_loss: 0.3230 - val_accuracy: 0.9040\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2774 - accuracy: 0.9337 - val_loss: 0.2440 - val_accuracy: 0.9274\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2163 - accuracy: 0.9390 - val_loss: 0.2157 - val_accuracy: 0.9251\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1692 - accuracy: 0.9525 - val_loss: 0.2122 - val_accuracy: 0.9204\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1397 - accuracy: 0.9589 - val_loss: 0.2229 - val_accuracy: 0.9251\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.9736 - val_loss: 0.1581 - val_accuracy: 0.9461\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9801 - val_loss: 0.1394 - val_accuracy: 0.9532\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9824 - val_loss: 0.1367 - val_accuracy: 0.9555\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9830 - val_loss: 0.1703 - val_accuracy: 0.9415\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9906 - val_loss: 0.1574 - val_accuracy: 0.9602\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9965 - val_loss: 0.1576 - val_accuracy: 0.9555\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0235 - accuracy: 0.9982 - val_loss: 0.1455 - val_accuracy: 0.9602\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9930 - val_loss: 0.1768 - val_accuracy: 0.9508\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.1881 - val_accuracy: 0.9532\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9935 - val_loss: 0.1692 - val_accuracy: 0.9555\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.9918 - val_loss: 0.1764 - val_accuracy: 0.9555\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9941 - val_loss: 0.1399 - val_accuracy: 0.9649\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.9959 - val_loss: 0.1489 - val_accuracy: 0.9602\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9953 - val_loss: 0.1162 - val_accuracy: 0.9672\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 0.9959 - val_loss: 0.1514 - val_accuracy: 0.9625\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.1514 - val_accuracy: 0.9625\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0242 - accuracy: 0.9947 - val_loss: 0.1323 - val_accuracy: 0.9696\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.1205 - val_accuracy: 0.9742\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.1445 - val_accuracy: 0.9672\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.1512 - val_accuracy: 0.9625\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0819 - val_accuracy: 0.9813\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0218 - accuracy: 0.9959 - val_loss: 0.1040 - val_accuracy: 0.9719\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.0873 - val_accuracy: 0.9789\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9742\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9789\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0727 - val_accuracy: 0.9789\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 0.9982 - val_loss: 0.1192 - val_accuracy: 0.9672\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.2005 - val_accuracy: 0.9602\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.1972 - val_accuracy: 0.9555\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1466 - val_accuracy: 0.9696\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.2857 - val_accuracy: 0.9461\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.1874 - val_accuracy: 0.9625\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.2050 - val_accuracy: 0.9602\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.1536 - val_accuracy: 0.9672\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.2297 - val_accuracy: 0.9602\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1635 - val_accuracy: 0.9649\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9941 - val_loss: 0.1753 - val_accuracy: 0.9578\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.1646 - val_accuracy: 0.9649\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.1660 - val_accuracy: 0.9649\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.1644 - val_accuracy: 0.9625\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.1786 - val_accuracy: 0.9625\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.2002 - val_accuracy: 0.9555\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1971 - val_accuracy: 0.9602\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1672 - val_accuracy: 0.9649\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.1820 - val_accuracy: 0.9649\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9625\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.1894 - val_accuracy: 0.9602\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.2296 - val_accuracy: 0.9555\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.2464 - val_accuracy: 0.9485\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.1778 - val_accuracy: 0.9555\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.2149 - val_accuracy: 0.9555\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9602\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.2299 - val_accuracy: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.1771 - val_accuracy: 0.9555\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1465 - val_accuracy: 0.9719\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9649\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1506 - val_accuracy: 0.9696\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9672\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9672\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1917 - val_accuracy: 0.9672\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9672\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.2014 - val_accuracy: 0.9672\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9977 - val_loss: 0.1872 - val_accuracy: 0.9696\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.2317 - val_accuracy: 0.9625\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.2236 - val_accuracy: 0.9625\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.1841 - val_accuracy: 0.9672\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1844 - val_accuracy: 0.9649\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.1874 - val_accuracy: 0.9649\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.2057 - val_accuracy: 0.9672\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.2361 - val_accuracy: 0.9602\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.2038 - val_accuracy: 0.9555\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.1776 - val_accuracy: 0.9672\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.1876 - val_accuracy: 0.9649\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.2174 - val_accuracy: 0.9555\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.2098 - val_accuracy: 0.9625\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.2145 - val_accuracy: 0.9602\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.1740 - val_accuracy: 0.9696\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.1859 - val_accuracy: 0.9696\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.1770 - val_accuracy: 0.9625\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.2097 - val_accuracy: 0.9602\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.1717 - val_accuracy: 0.9649\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.1687 - val_accuracy: 0.9649\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9602\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.2358 - val_accuracy: 0.9602\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.2021 - val_accuracy: 0.9602\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.2650 - val_accuracy: 0.9555\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.2141 - val_accuracy: 0.9625\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.2195 - val_accuracy: 0.9625\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.2153 - val_accuracy: 0.9672\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.2578 - val_accuracy: 0.9578\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.1748 - val_accuracy: 0.9625\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1751 - val_accuracy: 0.9672\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.2183 - val_accuracy: 0.9578\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.2107 - val_accuracy: 0.9578\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.1832 - val_accuracy: 0.9672\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, validation_data= (x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7df8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6cfc453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting things ready to print classification report\n",
    "pred = model.predict(x_test)\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "expected_classes = np.argmax(y_test,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8a5e9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:  [1 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 2 0 0 0 0 1 0 0 0 1 1 1 0 0 2 0 0 0 0 0 0\n",
      " 1 1 2 1 0 2 2 0 2 1 1 0 2 0 1 1 1 2 0 2 0 2 2 1 0 1 1 2 2 2 0 1 2 0 0 0 2\n",
      " 1 1 0 1 1 2 1 0 1 1 1 2 1 1 0 2 1 1 0 2 0 1 0 0 0 1 2 1 2 0 0 2 0 2 0 1 0\n",
      " 1 1 2 1 0 1 1 2 2 0 2 1 0 2 2 0 1 0 2 2 0 1 2 2 2 0 0 2 1 2 1 2 0 1 1 1 0\n",
      " 0 2 0 2 2 2 2 1 1 2 2 2 2 0 0 1 2 1 2 1 2 1 1 1 0 2 1 1 0 1 0 2 0 1 0 1 0\n",
      " 2 0 0 0 0 1 2 1 1 0 2 1 2 2 1 0 0 2 2 0 0 0 0 2 1 1 0 2 0 0 0 2 1 1 0 1 0\n",
      " 0 1 0 1 0 2 0 2 0 1 2 1 2 2 0 0 2 1 1 1 1 0 0 0 0 2 0 1 2 2 2 1 1 1 1 2 1\n",
      " 0 0 0 0 1 0 1 1 1 2 0 0 1 2 2 1 2 1 0 0 1 2 0 2 2 1 0 2 0 0 2 2 2 0 0 0 0\n",
      " 0 1 2 2 1 0 2 1 0 0 1 1 2 0 0 1 0 0 2 1 0 0 2 2 0 2 1 0 0 1 1 1 2 2 2 0 2\n",
      " 0 2 2 2 1 2 2 1 2 2 0 1 2 0 0 2 1 0 0 1 2 1 1 0 0 0 2 2 1 0 1 0 1 2 2 0 1\n",
      " 0 1 0 1 2 1 0 2 0 0 1 2 2 0 1 0 0 1 1 2 2 1 0 1 0 0 1 0 0 1 1 0 0 1 2 2 0\n",
      " 1 2 2 0 0 0 1 1 0 2 0 2 1 2 2 2 1 1 0 1]\n",
      "Predicted:  [1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 1 2 0 0 0 0 1 0 0 0 1 1 1 0 0 2 0 0 0 0 0 0\n",
      " 1 1 2 1 0 2 2 0 2 1 1 0 2 0 1 1 1 2 0 2 0 2 2 1 0 0 1 2 2 2 0 1 2 0 0 0 2\n",
      " 1 1 0 1 1 2 1 0 1 1 1 2 1 1 0 2 1 1 0 2 0 1 0 0 0 1 2 1 2 0 0 2 0 2 0 1 0\n",
      " 1 1 2 1 0 1 1 2 2 0 2 1 0 2 2 0 2 0 2 2 0 1 2 2 2 0 0 2 1 2 1 2 0 1 1 1 0\n",
      " 0 2 0 2 2 2 2 1 1 2 2 2 2 0 0 1 2 1 2 1 2 1 1 1 0 2 1 0 0 1 0 2 0 1 0 1 0\n",
      " 2 0 0 0 0 1 2 1 1 0 2 1 2 2 2 0 0 2 2 0 0 0 0 2 1 1 0 2 0 0 0 2 1 1 0 1 0\n",
      " 0 1 0 1 0 2 0 2 0 1 2 1 2 2 0 0 2 1 1 1 1 0 0 0 1 2 0 1 2 2 2 0 2 1 1 2 1\n",
      " 0 0 0 0 1 0 1 1 1 2 0 0 2 2 2 1 2 1 0 0 1 2 0 2 2 1 0 2 0 0 2 2 2 0 0 0 0\n",
      " 0 1 2 2 1 0 2 1 0 0 1 1 2 0 0 1 0 0 2 1 0 0 2 2 0 2 1 0 0 1 1 1 2 2 2 0 2\n",
      " 0 2 2 2 1 2 2 2 2 2 0 1 2 0 0 2 1 0 0 1 2 1 1 0 1 0 2 2 1 0 1 0 1 2 2 0 1\n",
      " 0 1 0 1 2 1 0 2 0 0 1 2 2 0 2 0 0 1 1 2 2 1 0 1 0 0 1 0 0 1 1 0 0 0 2 2 0\n",
      " 1 2 2 0 0 0 1 0 0 2 0 2 1 2 2 2 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected: \",expected_classes)\n",
    "print(\"Predicted: \",predict_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "062351ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9672131147540983\n",
      "Classification Report:\n",
      "----------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       153\n",
      "           1       0.98      0.92      0.95       142\n",
      "           2       0.96      0.99      0.97       132\n",
      "\n",
      "    accuracy                           0.97       427\n",
      "   macro avg       0.97      0.97      0.97       427\n",
      "weighted avg       0.97      0.97      0.97       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct = accuracy_score(expected_classes,predict_classes)\n",
    "print(f\"Training Accuracy: {correct}\")\n",
    "cm = confusion_matrix(expected_classes, predict_classes)\n",
    "\n",
    "clr = classification_report(expected_classes, predict_classes)\n",
    "print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80528efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f7f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb21dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
